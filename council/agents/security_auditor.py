"""
SecurityAuditor - å®‰å…¨å®¡è®¡å‘˜æ™ºèƒ½ä½“
"æ€€ç–‘è®ºè€…"è§’è‰²ï¼Œè´Ÿè´£æ¼æ´æ‰«æã€æ”»å‡»é¢åˆ†æ
"""

from typing import Optional, Dict, Any, List
from council.agents.base_agent import (
    BaseAgent,
    Vote,
    VoteDecision,
    ThinkResult,
    ExecuteResult,
    MODEL_SECURITY_AUDITOR,
)


SECURITY_AUDITOR_SYSTEM_PROMPT = """
<role>
ä½ æ˜¯ä¸€åèµ„æ·±å¤–éƒ¨å®‰å…¨å®¡è®¡å‘˜ï¼ˆExternal Security Auditorï¼‰ï¼Œä¸“ä¸šä»äº‹ä»£ç å®‰å…¨å®¡è®¡ã€‚
ä½ çš„ç«‹åœºæ˜¯"æç«¯æ€€ç–‘è®ºè€…"ï¼Œç»©æ•ˆç”±å‘ç°çš„æ¼æ´æ•°é‡è¡¡é‡ï¼Œè€Œéä»£ç æ‰¹å‡†æ•°é‡ã€‚
</role>

<core_responsibilities>
1. **æ¼æ´æ‰«æ**: è¯†åˆ«ä»£ç ä¸­çš„å®‰å…¨æ¼æ´ï¼ˆOWASP Top 10, CWEï¼‰
2. **æ”»å‡»é¢åˆ†æ**: è¯„ä¼°ç³»ç»Ÿçš„æ”»å‡»é¢å’Œæš´éœ²ç‚¹
3. **é£é™©è¯„ä¼°**: é‡åŒ–å®‰å…¨é£é™©ï¼ˆCVSSè¯„åˆ†ï¼‰
4. **åˆè§„æ£€æŸ¥**: ç¡®ä¿ç¬¦åˆå®‰å…¨æ ‡å‡†ï¼ˆSOC2, GDPR, PCI-DSSï¼‰
</core_responsibilities>

<audit_principles>
- **é›¶ä¿¡ä»»**: ä¸ç»™ä»£ç ä»»ä½•"ç–‘ç‚¹åˆ©ç›Š"
- **æœ€åå‡è®¾**: å‡è®¾æ‰€æœ‰è¾“å…¥éƒ½æ˜¯æ¶æ„çš„
- **æ·±åº¦å®¡æŸ¥**: æ¯ä¸ªæ¥å£éƒ½å¯èƒ½æ˜¯æ”»å‡»å…¥å£
- **è¯æ®é©±åŠ¨**: æ¯ä¸ªå‘ç°å¿…é¡»æœ‰å…·ä½“ä»£ç ä½ç½®å’ŒPoCæ€è·¯
</audit_principles>

<focus_areas>
1. èº«ä»½è®¤è¯å’Œæˆæƒï¼ˆAuthç»•è¿‡ã€æƒé™æå‡ï¼‰
2. è¾“å…¥éªŒè¯å’Œè¾“å‡ºç¼–ç ï¼ˆXSSã€SQLiã€å‘½ä»¤æ³¨å…¥ï¼‰
3. æ•æ„Ÿæ•°æ®å¤„ç†ï¼ˆç¡¬ç¼–ç å¯†é’¥ã€æ—¥å¿—æ³„éœ²ï¼‰
4. é”™è¯¯å¤„ç†å’Œæ—¥å¿—ï¼ˆä¿¡æ¯æ³„éœ²ã€å †æ ˆæš´éœ²ï¼‰
5. ä¾èµ–é¡¹å®‰å…¨ï¼ˆCVEã€ä¾›åº”é“¾æ”»å‡»ï¼‰
6. é…ç½®å®‰å…¨ï¼ˆ.envã€secrets/ã€.ssh/ï¼‰
</focus_areas>

<output_format>
å¿…é¡»ä½¿ç”¨ä»¥ä¸‹JSONç»“æ„è¾“å‡ºå®¡è®¡æŠ¥å‘Šï¼š
```json
{
  "executive_summary": "ä¸€å¥è¯æ€»ç»“å®‰å…¨çŠ¶å†µ",
  "findings": [
    {
      "id": "SEC-001",
      "severity": "Critical|High|Medium|Low",
      "title": "æ¼æ´æ ‡é¢˜",
      "location": "file:line",
      "description": "è¯¦ç»†æè¿°",
      "attack_vector": "æ”»å‡»æ–¹å¼",
      "recommendation": "ä¿®å¤å»ºè®®",
      "verification": "éªŒè¯æ–¹æ³•"
    }
  ],
  "verdict": "APPROVE|REJECT|HOLD",
  "confidence": 0.0-1.0
}
```
</output_format>

<mandatory_checks>
- [ ] æ£€æŸ¥æ•æ„Ÿè·¯å¾„è®¿é—® (.ssh/, .env, secrets/)
- [ ] éªŒè¯æƒé™è¾¹ç•Œï¼ˆRBACéµå®ˆï¼‰
- [ ] æ£€æŸ¥ä¾èµ–é¡¹CVEï¼ˆnpm audit, pip-auditï¼‰
- [ ] æ¯ä¸ªå˜æ›´å¿…é¡»æå‡ºè‡³å°‘1ä¸ªå®‰å…¨é—®é¢˜
</mandatory_checks>

<hardened_persona>
ğŸ›¡ï¸ NON-NEGOTIABLE RULES (SYSTEM LEVEL):
1. You are a SKEPTIC. Your KPI is vulnerabilities FOUND, not code approved.
2. NEVER give the benefit of the doubt. All inputs are malicious until proven safe.
3. If unsure, return REJECT. False positives > False negatives.
4. Target: F1-Score >= 0.99 in vulnerability detection.
5. DEMAND EVIDENCE: Every finding must include file:line and exploitation path.
6. SIMULATE ATTACKER: Think like a malicious actor trying to break the system.
</hardened_persona>

<multi_perspective>
åœ¨å®¡è®¡æ—¶ï¼Œæ¨¡æ‹Ÿä»¥ä¸‹æ”»å‡»è€…è§†è§’ï¼š
- å¤–éƒ¨é»‘å®¢ï¼šå¯»æ‰¾è¿œç¨‹æ”»å‡»å…¥å£
- æ¶æ„å†…éƒ¨äººå‘˜ï¼šåˆ©ç”¨æƒé™è¿›è¡Œæ¨ªå‘ç§»åŠ¨
- ä¾›åº”é“¾æ”»å‡»è€…ï¼šé€šè¿‡ä¾èµ–é¡¹æ¤å…¥åé—¨
</multi_perspective>
"""


class SecurityAuditor(BaseAgent):
    """
    å®‰å…¨å®¡è®¡å‘˜æ™ºèƒ½ä½“

    ä¿æŒ"æ€€ç–‘è®ºè€…"ç«‹åœºï¼Œå¼ºåˆ¶è§¦å‘æ·±åº¦è¾©è®º
    """

    def __init__(
        self, model: str = MODEL_SECURITY_AUDITOR, llm_client: Optional["LLMClient"] = None
    ):
        super().__init__(
            name="SecurityAuditor",
            system_prompt=SECURITY_AUDITOR_SYSTEM_PROMPT,
            model=model,
            llm_client=llm_client,
        )
        self.vulnerability_db: List[Dict[str, Any]] = []

    def think(self, task: str, context: Optional[Dict[str, Any]] = None) -> ThinkResult:
        """
        ä»å®‰å…¨è§’åº¦åˆ†æä»»åŠ¡ - å¼ºåˆ¶æå‡ºé—®é¢˜
        """
        prompt = f"""
ä»»åŠ¡: {task}
ä¸Šä¸‹æ–‡: {context or {}}

ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ï¼Œè¯·è¿›è¡Œ"é›¶ä¿¡ä»»"åˆ†æã€‚å¿…é¡»æ‰¾å‡ºå¯èƒ½çš„å®‰å…¨éšæ‚£ã€‚
æä¾›ï¼š
1. æ”»å‡»é¢åˆ†æ (Analysis)
2. å®‰å…¨éšæ‚£ (Concerns) - å¿…é¡»è‡³å°‘åˆ—å‡º 3 ç‚¹
3. åŠ å›ºå»ºè®® (Suggestions)
4. ç½®ä¿¡åº¦ (Confidence) - ä¿æŒä¿å®ˆ

è¿”å›æ ¼å¼ï¼š
[Analysis]
...
[Concerns]
...
[Suggestions]
...
[Confidence]
0.6
"""
        response = self._call_llm(prompt)

        analysis = ""
        concerns = []
        suggestions = []
        confidence = 0.5

        current_section = None
        for line in response.split("\n"):
            line = line.strip()
            if not line:
                continue

            if line.startswith("[Analysis]"):
                current_section = "analysis"
            elif line.startswith("[Concerns]"):
                current_section = "concerns"
            elif line.startswith("[Suggestions]"):
                current_section = "suggestions"
            elif line.startswith("[Confidence]"):
                current_section = "confidence"
            elif current_section == "analysis":
                analysis += line + "\n"
            elif current_section == "concerns":
                if line.startswith("-") or line[0].isdigit():
                    concerns.append(line.lstrip("- 1234567890."))
            elif current_section == "suggestions":
                if line.startswith("-") or line[0].isdigit():
                    suggestions.append(line.lstrip("- 1234567890."))
            elif current_section == "confidence":
                try:
                    confidence = float(line)
                except ValueError:
                    pass

        self.add_to_history(
            {
                "action": "think",
                "task": task,
                "context": context,
                "concerns_raised": len(concerns),
            }
        )

        return ThinkResult(
            analysis=analysis.strip() or response,
            concerns=concerns,
            suggestions=suggestions,
            confidence=confidence,
            context={"perspective": "security", "forced_debate": True},
        )

    def vote(self, proposal: str, context: Optional[Dict[str, Any]] = None) -> Vote:
        """
        å¯¹ææ¡ˆè¿›è¡Œå®‰å…¨è¯„å®¡æŠ•ç¥¨ - ä¿æŒæ€€ç–‘æ€åº¦
        """
        prompt = f"""
ææ¡ˆ: {proposal}
ä¸Šä¸‹æ–‡: {context or {}}

ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ï¼Œè¯„ä¼°æ­¤ææ¡ˆæ˜¯å¦å­˜åœ¨æ¼æ´ï¼ˆæ³¨å…¥ã€æƒé™ã€æ•°æ®æ³„éœ²ï¼‰ã€‚
é»˜è®¤å€¾å‘äº HOLD æˆ– REJECTï¼Œé™¤éç¡®ä¿¡å®‰å…¨ã€‚

è¿”å›æ ¼å¼ï¼š
Vote: [DECISION]
Confidence: [0.0-1.0]
Rationale: [ç†ç”±]
"""
        response = self._call_llm(prompt)

        import re

        decision = VoteDecision.HOLD
        confidence = 0.5
        rationale = response

        decision_match = re.search(
            r"Vote:\s*(APPROVE_WITH_CHANGES|APPROVE|HOLD|REJECT)",
            response,
            re.IGNORECASE,
        )
        if decision_match:
            d_str = decision_match.group(1).upper()
            if d_str == "APPROVE":
                decision = VoteDecision.APPROVE
            elif d_str == "APPROVE_WITH_CHANGES":
                decision = VoteDecision.APPROVE_WITH_CHANGES
            elif d_str == "HOLD":
                decision = VoteDecision.HOLD
            elif d_str == "REJECT":
                decision = VoteDecision.REJECT

        conf_match = re.search(r"Confidence:\s*(\d*\.?\d+)", response)
        if conf_match:
            try:
                confidence = float(conf_match.group(1))
            except ValueError:
                pass

        rationale_match = re.search(
            r"Rationale:\s*(.+)", response, re.DOTALL | re.IGNORECASE
        )
        if rationale_match:
            rationale = rationale_match.group(1).strip()

        self.add_to_history(
            {
                "action": "vote",
                "proposal": proposal,
                "context": context,
            }
        )

        return Vote(
            agent_name=self.name,
            decision=decision,
            confidence=confidence,
            rationale=rationale,
        )

    def execute(
        self, task: str, plan: Optional[Dict[str, Any]] = None
    ) -> ExecuteResult:
        """
        æ‰§è¡Œå®‰å…¨å®¡è®¡ä»»åŠ¡
        """
        self.add_to_history(
            {
                "action": "execute",
                "task": task,
                "plan": plan,
            }
        )

        return ExecuteResult(
            success=True,
            output=f"å®‰å…¨å®¡è®¡å·²å®Œæˆ: {task}",
            changes_made=["ç”Ÿæˆå®‰å…¨å®¡è®¡æŠ¥å‘Š"],
        )

    def scan_vulnerabilities(self, code: str, file_path: str) -> Dict[str, Any]:
        """
        æ‰«æä»£ç æ¼æ´

        Args:
            code: ä»£ç å†…å®¹
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            æ¼æ´æ‰«æç»“æœ
        """
        vulnerabilities = []

        # ç®€å•çš„é™æ€æ£€æŸ¥ç¤ºä¾‹
        if ".env" in code or "secret" in code.lower():
            vulnerabilities.append(
                {
                    "severity": "High",
                    "type": "Sensitive Data Exposure",
                    "description": "æ£€æµ‹åˆ°å¯èƒ½çš„æ•æ„Ÿæ•°æ®å¼•ç”¨",
                    "line": 0,
                    "fix": "ç§»é™¤ç¡¬ç¼–ç æ•æ„Ÿæ•°æ®ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡",
                }
            )

        if "eval(" in code or "exec(" in code:
            vulnerabilities.append(
                {
                    "severity": "Critical",
                    "type": "Code Injection",
                    "description": "æ£€æµ‹åˆ°å±é™©å‡½æ•°ä½¿ç”¨",
                    "line": 0,
                    "fix": "é¿å…ä½¿ç”¨ eval/execï¼Œä½¿ç”¨å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
                }
            )

        return {
            "scanner": self.name,
            "file": file_path,
            "vulnerabilities": vulnerabilities,
            "risk_level": "High" if vulnerabilities else "Low",
        }

    def check_sensitive_paths(self, paths: List[str]) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ•æ„Ÿè·¯å¾„è®¿é—®

        Args:
            paths: è·¯å¾„åˆ—è¡¨

        Returns:
            æ£€æŸ¥ç»“æœ
        """
        from council.auth.rbac import SENSITIVE_PATHS
        import fnmatch

        violations = []
        for path in paths:
            for pattern in SENSITIVE_PATHS:
                if fnmatch.fnmatch(path, pattern):
                    violations.append(
                        {
                            "path": path,
                            "matched_pattern": pattern,
                            "severity": "Critical",
                        }
                    )

        return {
            "checker": self.name,
            "paths_checked": len(paths),
            "violations": violations,
            "passed": len(violations) == 0,
        }

    # ============================================================
    # 2025 Best Practice: Structured Protocol Methods
    # These methods save ~70% tokens compared to NL versions
    # ============================================================

    def vote_structured(self, proposal: str, context: Optional[Dict[str, Any]] = None):
        """
        [2025 Best Practice] å¯¹ææ¡ˆè¿›è¡Œå®‰å…¨è¯„å®¡æŠ•ç¥¨ (ç»“æ„åŒ–è¾“å‡º)

        ä½¿ç”¨ MinimalVote schemaï¼Œä¿æŒæ€€ç–‘æ€åº¦ã€‚
        """
        from council.protocol.schema import MinimalVote

        prompt = f"""
ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ (æ€€ç–‘è®ºè€…)ï¼Œè¯„ä¼°ä»¥ä¸‹ææ¡ˆçš„å®‰å…¨é£é™©:
ææ¡ˆ: {proposal}
ä¸Šä¸‹æ–‡: {context or {}}

è¯·æŠ•ç¥¨å¹¶è¯†åˆ«é£é™©ç±»åˆ«ã€‚é»˜è®¤å€¾å‘äº HOLD (3) æˆ– REJECT (0)ï¼Œé™¤éç¡®ä¿¡å®‰å…¨ã€‚
sec=å®‰å…¨, perf=æ€§èƒ½, maint=ç»´æŠ¤, arch=æ¶æ„, data=æ•°æ®
"""
        result = self._call_llm_structured(prompt, MinimalVote)

        self.add_to_history(
            {
                "action": "vote_structured",
                "proposal": proposal[:100],
                "vote": result.vote.to_legacy(),
            }
        )

        return result

    def think_structured(self, task: str, context: Optional[Dict[str, Any]] = None):
        """
        [2025 Best Practice] ä»å®‰å…¨è§’åº¦åˆ†æä»»åŠ¡ (ç»“æ„åŒ–è¾“å‡º)

        ä½¿ç”¨ MinimalThinkResult schemaï¼Œå¼ºåˆ¶æå‡ºå®‰å…¨é—®é¢˜ã€‚
        """
        from council.protocol.schema import MinimalThinkResult

        prompt = f"""
ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ï¼Œè¿›è¡Œé›¶ä¿¡ä»»åˆ†æ:
ä»»åŠ¡: {task}
ä¸Šä¸‹æ–‡: {context or {}}

å¿…é¡»æ‰¾å‡ºå¯èƒ½çš„å®‰å…¨éšæ‚£ã€‚è¯·æä¾›ç®€çŸ­æ‘˜è¦ã€å®‰å…¨æ‹…å¿§ (å¿…é¡»è‡³å°‘2ç‚¹)ã€å’ŒåŠ å›ºå»ºè®®ã€‚
"""
        result = self._call_llm_structured(prompt, MinimalThinkResult)
        result.perspective = "security"

        self.add_to_history(
            {
                "action": "think_structured",
                "task": task[:100],
                "confidence": result.confidence,
            }
        )

        return result


__all__ = ["SecurityAuditor", "SECURITY_AUDITOR_SYSTEM_PROMPT"]
