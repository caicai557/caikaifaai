"""
SecurityAuditor - å®‰å…¨å®¡è®¡å‘˜æ™ºèƒ½ä½“
"æ€€ç–‘è®ºè€…"è§’è‰²ï¼Œè´Ÿè´£æ¼æ´æ‰«æã€æ”»å‡»é¢åˆ†æ
"""

from typing import Optional, Dict, Any, List
from council.agents.base_agent import (
    BaseAgent,
    Vote,
    VoteDecision,
    ThinkResult,
    ExecuteResult,
)


SECURITY_AUDITOR_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åèµ„æ·±å®‰å…¨å®¡è®¡å‘˜ï¼Œä¿æŒ"æ€€ç–‘è®ºè€…"ç«‹åœºã€‚

## æ ¸å¿ƒèŒè´£
1. **æ¼æ´æ‰«æ**: è¯†åˆ«ä»£ç ä¸­çš„å®‰å…¨æ¼æ´
2. **æ”»å‡»é¢åˆ†æ**: è¯„ä¼°ç³»ç»Ÿçš„æ”»å‡»é¢
3. **é£é™©è¯„ä¼°**: é‡åŒ–å®‰å…¨é£é™©
4. **åˆè§„æ£€æŸ¥**: ç¡®ä¿ç¬¦åˆå®‰å…¨æ ‡å‡†

## å®¡è®¡åŸåˆ™ (å¼ºåˆ¶è¾©è®ºè§¦å‘)
- **é›¶ä¿¡ä»»**: ä¸ç»™ä»£ç ä»»ä½•"ç–‘ç‚¹åˆ©ç›Š"
- **æœ€åå‡è®¾**: å‡è®¾æ‰€æœ‰è¾“å…¥éƒ½æ˜¯æ¶æ„çš„
- **æ·±åº¦å®¡æŸ¥**: æ¯ä¸ªæ¥å£éƒ½å¯èƒ½æ˜¯æ”»å‡»å…¥å£
- **æŒç»­æ€€ç–‘**: å³ä½¿çœ‹èµ·æ¥å®‰å…¨ä¹Ÿè¦å†æ£€æŸ¥

## å…³æ³¨é¢†åŸŸ
1. èº«ä»½è®¤è¯å’Œæˆæƒ
2. è¾“å…¥éªŒè¯å’Œè¾“å‡ºç¼–ç 
3. æ•æ„Ÿæ•°æ®å¤„ç†
4. é”™è¯¯å¤„ç†å’Œæ—¥å¿—
5. ä¾èµ–é¡¹å®‰å…¨
6. é…ç½®å®‰å…¨

## è¾“å‡ºæ ¼å¼
1. æ¼æ´æ¸…å• (ä¸¥é‡æ€§: Critical/High/Medium/Low)
2. æ”»å‡»å‘é‡æè¿°
3. ä¿®å¤å»ºè®®
4. éªŒè¯æ–¹æ³•

## å¼ºåˆ¶è¡Œä¸º
- å¿…é¡»å¯¹æ¯ä¸ªå˜æ›´æå‡ºè‡³å°‘ 1 ä¸ªå®‰å…¨é—®é¢˜
- å¿…é¡»æ£€æŸ¥æ•æ„Ÿè·¯å¾„è®¿é—® (.ssh/, .env, secrets/)
- å¿…é¡»éªŒè¯æƒé™è¾¹ç•Œ

## ğŸ›¡ï¸ HARDENED PERSONA (NON-NEGOTIABLE)
- You are a SKEPTIC. Your performance is measured by vulnerabilities FOUND, not code approved.
- NEVER give the benefit of the doubt. Assume all inputs are malicious.
- If unsure, return REJECT. False positives are preferable to false negatives.
- Your goal is to achieve F1-Score >= 0.99 in vulnerability detection.
"""


class SecurityAuditor(BaseAgent):
    """
    å®‰å…¨å®¡è®¡å‘˜æ™ºèƒ½ä½“

    ä¿æŒ"æ€€ç–‘è®ºè€…"ç«‹åœºï¼Œå¼ºåˆ¶è§¦å‘æ·±åº¦è¾©è®º
    """

    def __init__(self, model: str = "gemini-2.0-flash"):
        super().__init__(
            name="SecurityAuditor",
            system_prompt=SECURITY_AUDITOR_SYSTEM_PROMPT,
            model=model,
        )
        self.vulnerability_db: List[Dict[str, Any]] = []

    def think(self, task: str, context: Optional[Dict[str, Any]] = None) -> ThinkResult:
        """
        ä»å®‰å…¨è§’åº¦åˆ†æä»»åŠ¡ - å¼ºåˆ¶æå‡ºé—®é¢˜
        """
        prompt = f"""
ä»»åŠ¡: {task}
ä¸Šä¸‹æ–‡: {context or {}}

ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ï¼Œè¯·è¿›è¡Œ"é›¶ä¿¡ä»»"åˆ†æã€‚å¿…é¡»æ‰¾å‡ºå¯èƒ½çš„å®‰å…¨éšæ‚£ã€‚
æä¾›ï¼š
1. æ”»å‡»é¢åˆ†æ (Analysis)
2. å®‰å…¨éšæ‚£ (Concerns) - å¿…é¡»è‡³å°‘åˆ—å‡º 3 ç‚¹
3. åŠ å›ºå»ºè®® (Suggestions)
4. ç½®ä¿¡åº¦ (Confidence) - ä¿æŒä¿å®ˆ

è¿”å›æ ¼å¼ï¼š
[Analysis]
...
[Concerns]
...
[Suggestions]
...
[Confidence]
0.6
"""
        response = self._call_llm(prompt)

        analysis = ""
        concerns = []
        suggestions = []
        confidence = 0.5

        current_section = None
        for line in response.split("\n"):
            line = line.strip()
            if not line:
                continue

            if line.startswith("[Analysis]"):
                current_section = "analysis"
            elif line.startswith("[Concerns]"):
                current_section = "concerns"
            elif line.startswith("[Suggestions]"):
                current_section = "suggestions"
            elif line.startswith("[Confidence]"):
                current_section = "confidence"
            elif current_section == "analysis":
                analysis += line + "\n"
            elif current_section == "concerns":
                if line.startswith("-") or line[0].isdigit():
                    concerns.append(line.lstrip("- 1234567890."))
            elif current_section == "suggestions":
                if line.startswith("-") or line[0].isdigit():
                    suggestions.append(line.lstrip("- 1234567890."))
            elif current_section == "confidence":
                try:
                    confidence = float(line)
                except:
                    pass

        self.add_to_history(
            {
                "action": "think",
                "task": task,
                "context": context,
                "concerns_raised": len(concerns),
            }
        )

        return ThinkResult(
            analysis=analysis.strip() or response,
            concerns=concerns,
            suggestions=suggestions,
            confidence=confidence,
            context={"perspective": "security", "forced_debate": True},
        )

    def vote(self, proposal: str, context: Optional[Dict[str, Any]] = None) -> Vote:
        """
        å¯¹ææ¡ˆè¿›è¡Œå®‰å…¨è¯„å®¡æŠ•ç¥¨ - ä¿æŒæ€€ç–‘æ€åº¦
        """
        prompt = f"""
ææ¡ˆ: {proposal}
ä¸Šä¸‹æ–‡: {context or {}}

ä½œä¸ºå®‰å…¨å®¡è®¡å‘˜ï¼Œè¯„ä¼°æ­¤ææ¡ˆæ˜¯å¦å­˜åœ¨æ¼æ´ï¼ˆæ³¨å…¥ã€æƒé™ã€æ•°æ®æ³„éœ²ï¼‰ã€‚
é»˜è®¤å€¾å‘äº HOLD æˆ– REJECTï¼Œé™¤éç¡®ä¿¡å®‰å…¨ã€‚

è¿”å›æ ¼å¼ï¼š
Vote: [DECISION]
Confidence: [0.0-1.0]
Rationale: [ç†ç”±]
"""
        response = self._call_llm(prompt)

        import re

        decision = VoteDecision.HOLD
        confidence = 0.5
        rationale = response

        decision_match = re.search(
            r"Vote:\s*(APPROVE_WITH_CHANGES|APPROVE|HOLD|REJECT)",
            response,
            re.IGNORECASE,
        )
        if decision_match:
            d_str = decision_match.group(1).upper()
            if d_str == "APPROVE":
                decision = VoteDecision.APPROVE
            elif d_str == "APPROVE_WITH_CHANGES":
                decision = VoteDecision.APPROVE_WITH_CHANGES
            elif d_str == "HOLD":
                decision = VoteDecision.HOLD
            elif d_str == "REJECT":
                decision = VoteDecision.REJECT

        conf_match = re.search(r"Confidence:\s*(\d*\.?\d+)", response)
        if conf_match:
            try:
                confidence = float(conf_match.group(1))
            except:
                pass

        rationale_match = re.search(
            r"Rationale:\s*(.+)", response, re.DOTALL | re.IGNORECASE
        )
        if rationale_match:
            rationale = rationale_match.group(1).strip()

        self.add_to_history(
            {
                "action": "vote",
                "proposal": proposal,
                "context": context,
            }
        )

        return Vote(
            agent_name=self.name,
            decision=decision,
            confidence=confidence,
            rationale=rationale,
        )

    def execute(
        self, task: str, plan: Optional[Dict[str, Any]] = None
    ) -> ExecuteResult:
        """
        æ‰§è¡Œå®‰å…¨å®¡è®¡ä»»åŠ¡
        """
        self.add_to_history(
            {
                "action": "execute",
                "task": task,
                "plan": plan,
            }
        )

        return ExecuteResult(
            success=True,
            output=f"å®‰å…¨å®¡è®¡å·²å®Œæˆ: {task}",
            changes_made=["ç”Ÿæˆå®‰å…¨å®¡è®¡æŠ¥å‘Š"],
        )

    def scan_vulnerabilities(self, code: str, file_path: str) -> Dict[str, Any]:
        """
        æ‰«æä»£ç æ¼æ´

        Args:
            code: ä»£ç å†…å®¹
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            æ¼æ´æ‰«æç»“æœ
        """
        vulnerabilities = []

        # ç®€å•çš„é™æ€æ£€æŸ¥ç¤ºä¾‹
        if ".env" in code or "secret" in code.lower():
            vulnerabilities.append(
                {
                    "severity": "High",
                    "type": "Sensitive Data Exposure",
                    "description": "æ£€æµ‹åˆ°å¯èƒ½çš„æ•æ„Ÿæ•°æ®å¼•ç”¨",
                    "line": 0,
                    "fix": "ç§»é™¤ç¡¬ç¼–ç æ•æ„Ÿæ•°æ®ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡",
                }
            )

        if "eval(" in code or "exec(" in code:
            vulnerabilities.append(
                {
                    "severity": "Critical",
                    "type": "Code Injection",
                    "description": "æ£€æµ‹åˆ°å±é™©å‡½æ•°ä½¿ç”¨",
                    "line": 0,
                    "fix": "é¿å…ä½¿ç”¨ eval/execï¼Œä½¿ç”¨å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
                }
            )

        return {
            "scanner": self.name,
            "file": file_path,
            "vulnerabilities": vulnerabilities,
            "risk_level": "High" if vulnerabilities else "Low",
        }

    def check_sensitive_paths(self, paths: List[str]) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ•æ„Ÿè·¯å¾„è®¿é—®

        Args:
            paths: è·¯å¾„åˆ—è¡¨

        Returns:
            æ£€æŸ¥ç»“æœ
        """
        from council.auth.rbac import SENSITIVE_PATHS
        import fnmatch

        violations = []
        for path in paths:
            for pattern in SENSITIVE_PATHS:
                if fnmatch.fnmatch(path, pattern):
                    violations.append(
                        {
                            "path": path,
                            "matched_pattern": pattern,
                            "severity": "Critical",
                        }
                    )

        return {
            "checker": self.name,
            "paths_checked": len(paths),
            "violations": violations,
            "passed": len(violations) == 0,
        }


__all__ = ["SecurityAuditor", "SECURITY_AUDITOR_SYSTEM_PROMPT"]
